{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scraping Assignment 4\n",
    "# Samrat Dey\n",
    "# Batch - DS2312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20a97e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views(billions)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>14.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Roar\"[42]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Lakdi Ki Kathi\"[43]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[44]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Shree Hanuman Chalisa\"[48]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Dark Horse\"[49]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Perfect\"[50]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Let Her Go\"[51]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Faded\"[52]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "Rank                                                    \n",
       "1                               \"Baby Shark Dance\"[6]   \n",
       "2                                      \"Despacito\"[9]   \n",
       "3                          \"Johny Johny Yes Papa\"[17]   \n",
       "4                                     \"Bath Song\"[18]   \n",
       "5                                  \"Shape of You\"[19]   \n",
       "6                                 \"See You Again\"[22]   \n",
       "7                             \"Wheels on the Bus\"[27]   \n",
       "8                   \"Phonics Song with Two Words\"[28]   \n",
       "9                                   \"Uptown Funk\"[29]   \n",
       "10    \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "11                                \"Gangnam Style\"[31]   \n",
       "12     \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "13                               \"Dame Tu Cosita\"[37]   \n",
       "14                                       \"Axel F\"[38]   \n",
       "15                                        \"Sugar\"[39]   \n",
       "16                               \"Counting Stars\"[40]   \n",
       "17                          \"Baa Baa Black Sheep\"[41]   \n",
       "18                                         \"Roar\"[42]   \n",
       "19                               \"Lakdi Ki Kathi\"[43]   \n",
       "20             \"Waka Waka (This Time for Africa)\"[44]   \n",
       "21                                        \"Sorry\"[45]   \n",
       "22                            \"Thinking Out Loud\"[46]   \n",
       "23            \"Humpty the train on a fruits ride\"[47]   \n",
       "24                        \"Shree Hanuman Chalisa\"[48]   \n",
       "25                                   \"Dark Horse\"[49]   \n",
       "26                                      \"Perfect\"[50]   \n",
       "27                                   \"Let Her Go\"[51]   \n",
       "28                                        \"Faded\"[52]   \n",
       "29                               \"Girls Like You\"[53]   \n",
       "30                                      \"Lean On\"[54]   \n",
       "\n",
       "                                                 Artist        Upload Date  \\\n",
       "Rank                                                                         \n",
       "1           Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "2                                            Luis Fonsi   January 12, 2017   \n",
       "3     LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "4                            Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "5                                            Ed Sheeran   January 30, 2017   \n",
       "6                                           Wiz Khalifa      April 6, 2015   \n",
       "7                            Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "8                 ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "9                                           Mark Ronson  November 19, 2014   \n",
       "10                                          Miroshka TV  February 27, 2018   \n",
       "11                                                  Psy      July 15, 2012   \n",
       "12                                           Get Movies   January 31, 2012   \n",
       "13                                        Ultra Records      April 5, 2018   \n",
       "14                                           Crazy Frog      June 16, 2009   \n",
       "15                                             Maroon 5   January 14, 2015   \n",
       "16                                          OneRepublic       May 31, 2013   \n",
       "17                           Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                           Katy Perry  September 5, 2013   \n",
       "19                                         Jingle Toons      June 14, 2018   \n",
       "20                                              Shakira       June 4, 2010   \n",
       "21                                        Justin Bieber   October 22, 2015   \n",
       "22                                           Ed Sheeran    October 7, 2014   \n",
       "23        Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "24                                T-Series Bhakti Sagar       May 10, 2011   \n",
       "25                                           Katy Perry  February 20, 2014   \n",
       "26                                           Ed Sheeran   November 9, 2017   \n",
       "27                                            Passenger      July 25, 2012   \n",
       "28                                          Alan Walker   December 3, 2015   \n",
       "29                                             Maroon 5       May 31, 2018   \n",
       "30                                 Major Lazer Official     March 22, 2015   \n",
       "\n",
       "     Views(billions)  \n",
       "Rank                  \n",
       "1              14.09  \n",
       "2               8.38  \n",
       "3               6.87  \n",
       "4               6.62  \n",
       "5               6.20  \n",
       "6               6.17  \n",
       "7               5.88  \n",
       "8               5.70  \n",
       "9               5.15  \n",
       "10              5.07  \n",
       "11              5.05  \n",
       "12              4.58  \n",
       "13              4.55  \n",
       "14              4.34  \n",
       "15              4.00  \n",
       "16              3.97  \n",
       "17              3.96  \n",
       "18              3.96  \n",
       "19              3.91  \n",
       "20              3.85  \n",
       "21              3.77  \n",
       "22              3.73  \n",
       "23              3.73  \n",
       "24              3.69  \n",
       "25              3.67  \n",
       "26              3.67  \n",
       "27              3.61  \n",
       "28              3.59  \n",
       "29              3.56  \n",
       "30              3.55  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.1 Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "# You need to find following details: A) Rank B) Name C) Artist D) Upload date E) Views\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import requests\n",
    "import time\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Date=[]\n",
    "Views=[]\n",
    "\n",
    "start=0\n",
    "end=1\n",
    "\n",
    "for page in range(start,end):\n",
    "    Name_tags=driver.find_elements(By.XPATH,'//table[@Class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "    for i in Name_tags:\n",
    "        try:\n",
    "            name=i.text\n",
    "            Name.append(name)\n",
    "        except:\n",
    "            Name.append('-')\n",
    "    Artist_tags=driver.find_elements(By.XPATH,'//table[@Class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "    for i in Artist_tags:\n",
    "        try:\n",
    "            artist=i.text\n",
    "            Artist.append(artist)\n",
    "        except:\n",
    "            Artist.append('-')\n",
    "    Date_tags=driver.find_elements(By.XPATH,'//table[@Class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "    for i in Date_tags:\n",
    "        try:\n",
    "            date=i.text\n",
    "            Date.append(date)\n",
    "        except:\n",
    "            Date.append('-')\n",
    "    Views_tags=driver.find_elements(By.XPATH,'//table[@Class=\"sortable wikitable sticky-header static-row-numbers sort-under col3center col4right jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "    for i in Views_tags:\n",
    "        try:\n",
    "            views=i.text\n",
    "            Views.append(views)\n",
    "        except:\n",
    "            Views.append('-')\n",
    "df=pd.DataFrame({'Name':Name,'Artist':Artist,'Upload Date':Date,'Views(billions)':Views})\n",
    "df.insert(0, 'Rank', range(1, 1 + len(df)))\n",
    "df.set_index('Rank',inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84798fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>Dharamsala</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare</td>\n",
       "      <td>6 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare</td>\n",
       "      <td>7 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare</td>\n",
       "      <td>10 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare</td>\n",
       "      <td>13 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE 2024</td>\n",
       "      <td>Harare</td>\n",
       "      <td>14 JULY, 2024</td>\n",
       "      <td>8:00 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Series       Place           Date         Time\n",
       "0  ENGLAND TOUR OF INDIA 2023-24  Dharamsala  7 MARCH, 2024  9:30 AM IST\n",
       "1    INDIA TOUR OF ZIMBABWE 2024      Harare   6 JULY, 2024  8:00 PM IST\n",
       "2    INDIA TOUR OF ZIMBABWE 2024      Harare   7 JULY, 2024  8:00 PM IST\n",
       "3    INDIA TOUR OF ZIMBABWE 2024      Harare  10 JULY, 2024  8:00 PM IST\n",
       "4    INDIA TOUR OF ZIMBABWE 2024      Harare  13 JULY, 2024  8:00 PM IST\n",
       "5    INDIA TOUR OF ZIMBABWE 2024      Harare  14 JULY, 2024  8:00 PM IST"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.2 Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.   \n",
    "# You need to find following details: A) Series B) Place C) Date D) Time\n",
    "# Note: - From bcci.tv home page you have reach to the international fixture page through code.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import requests\n",
    "import time\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "time.sleep(5)\n",
    "fixture=driver.find_element(By.XPATH,\"/html/body/header/div[3]/div[2]/ul/div[1]/a[2]\")\n",
    "fixture.click()\n",
    "time.sleep(5)\n",
    "\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "start=0\n",
    "end=1\n",
    "\n",
    "for page in range(start,end):\n",
    "    Series_tags=driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')\n",
    "    for i in Series_tags:\n",
    "        try:\n",
    "            series=i.text\n",
    "            Series.append(series)\n",
    "        except:\n",
    "            Series.append('-')\n",
    "    Place_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]/span[2]')\n",
    "    for i in Place_tags:\n",
    "        try:\n",
    "            place=i.text\n",
    "            Place.append(place)\n",
    "        except:\n",
    "            Place.append('-')\n",
    "    Date_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "    for i in Date_tags:\n",
    "        try:\n",
    "            date=i.text\n",
    "            Date.append(date)\n",
    "        except:\n",
    "            Date.append('-')\n",
    "    Time_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "    for i in Time_tags:\n",
    "        try:\n",
    "            time=i.text\n",
    "            Time.append(time)\n",
    "        except:\n",
    "            Time.append('-')\n",
    "df=pd.DataFrame({'Series':Series,'Place':Place,'Date':Date,'Time':Time})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e266b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(21-22) Cr INR at current prices</th>\n",
       "      <th>GSDP(22-23) Cr INR at current prices</th>\n",
       "      <th>Share(21-22)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>-</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>417.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>8.82%</td>\n",
       "      <td>278.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,974,532</td>\n",
       "      <td>2,257,575</td>\n",
       "      <td>8.41%</td>\n",
       "      <td>265.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,962,725</td>\n",
       "      <td>2,241,368</td>\n",
       "      <td>8.36%</td>\n",
       "      <td>263.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,937,066</td>\n",
       "      <td>-</td>\n",
       "      <td>8.25%</td>\n",
       "      <td>259.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,363,926</td>\n",
       "      <td>1,554,992</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>183.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,218,193</td>\n",
       "      <td>1,413,620</td>\n",
       "      <td>5.19%</td>\n",
       "      <td>163.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,136,137</td>\n",
       "      <td>1,322,821</td>\n",
       "      <td>4.84%</td>\n",
       "      <td>152.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,133,837</td>\n",
       "      <td>1,317,728</td>\n",
       "      <td>4.83%</td>\n",
       "      <td>152.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,128,907</td>\n",
       "      <td>1,313,391</td>\n",
       "      <td>4.81%</td>\n",
       "      <td>151.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>932,470</td>\n",
       "      <td>-</td>\n",
       "      <td>3.97%</td>\n",
       "      <td>125.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>904,642</td>\n",
       "      <td>1,043,759</td>\n",
       "      <td>3.85%</td>\n",
       "      <td>121.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>870,665</td>\n",
       "      <td>994,154</td>\n",
       "      <td>3.71%</td>\n",
       "      <td>116.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>670,881</td>\n",
       "      <td>774,869</td>\n",
       "      <td>2.86%</td>\n",
       "      <td>90.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>650,302</td>\n",
       "      <td>751,396</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>87.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>614,227</td>\n",
       "      <td>673,107</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>412,612</td>\n",
       "      <td>493,167</td>\n",
       "      <td>1.76%</td>\n",
       "      <td>55.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>406,416</td>\n",
       "      <td>457,608</td>\n",
       "      <td>1.73%</td>\n",
       "      <td>54.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>358,863</td>\n",
       "      <td>393,722</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>48.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>272,159</td>\n",
       "      <td>302,621</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>36.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir-UT</td>\n",
       "      <td>199,917</td>\n",
       "      <td>227,927</td>\n",
       "      <td>0.85%</td>\n",
       "      <td>26.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>176,269</td>\n",
       "      <td>195,405</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>23.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>82,604</td>\n",
       "      <td>-</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>11.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>62,550</td>\n",
       "      <td>72,636</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>45,635</td>\n",
       "      <td>-</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>6.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>44,238</td>\n",
       "      <td>-</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>38,785</td>\n",
       "      <td>42,697</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>5.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>37,557</td>\n",
       "      <td>42,756</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>36,594</td>\n",
       "      <td>-</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>35,124</td>\n",
       "      <td>-</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>31,913</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>27,824</td>\n",
       "      <td>-</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>10,371</td>\n",
       "      <td>-</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(21-22) Cr INR at current prices  \\\n",
       "0     1                Maharashtra                            3,108,022   \n",
       "1     2                 Tamil Nadu                            2,071,286   \n",
       "2     3              Uttar Pradesh                            1,974,532   \n",
       "3     4                  Karnataka                            1,962,725   \n",
       "4     5                    Gujarat                            1,937,066   \n",
       "5     6                West Bengal                            1,363,926   \n",
       "6     7                  Rajasthan                            1,218,193   \n",
       "7     8             Madhya Pradesh                            1,136,137   \n",
       "8     9             Andhra Pradesh                            1,133,837   \n",
       "9    10                  Telangana                            1,128,907   \n",
       "10   11                     Kerala                              932,470   \n",
       "11   12                      Delhi                              904,642   \n",
       "12   13                    Haryana                              870,665   \n",
       "13   14                     Odisha                              670,881   \n",
       "14   15                      Bihar                              650,302   \n",
       "15   16                     Punjab                              614,227   \n",
       "16   17                      Assam                              412,612   \n",
       "17   18               Chhattisgarh                              406,416   \n",
       "18   19                  Jharkhand                              358,863   \n",
       "19   20                Uttarakhand                              272,159   \n",
       "20   21         Jammu & Kashmir-UT                              199,917   \n",
       "21   22           Himachal Pradesh                              176,269   \n",
       "22   23                        Goa                               82,604   \n",
       "23   24                    Tripura                               62,550   \n",
       "24   25                 Chandigarh                               45,635   \n",
       "25   26                 Puducherry                               44,238   \n",
       "26   27                  Meghalaya                               38,785   \n",
       "27   28                     Sikkim                               37,557   \n",
       "28   29                    Manipur                               36,594   \n",
       "29   30          Arunachal Pradesh                               35,124   \n",
       "30   31                   Nagaland                               31,913   \n",
       "31   32                    Mizoram                               27,824   \n",
       "32   33  Andaman & Nicobar Islands                               10,371   \n",
       "\n",
       "   GSDP(22-23) Cr INR at current prices Share(21-22) GDP($ billion)  \n",
       "0                                     -       13.24%        417.163  \n",
       "1                             2,364,514        8.82%        278.011  \n",
       "2                             2,257,575        8.41%        265.024  \n",
       "3                             2,241,368        8.36%        263.440  \n",
       "4                                     -        8.25%        259.996  \n",
       "5                             1,554,992        5.81%        183.068  \n",
       "6                             1,413,620        5.19%        163.507  \n",
       "7                             1,322,821        4.84%        152.494  \n",
       "8                             1,317,728        4.83%        152.185  \n",
       "9                             1,313,391        4.81%        151.523  \n",
       "10                                    -        3.97%        125.157  \n",
       "11                            1,043,759        3.85%        121.422  \n",
       "12                              994,154        3.71%        116.862  \n",
       "13                              774,869        2.86%         90.047  \n",
       "14                              751,396        2.77%         87.284  \n",
       "15                              673,107        2.62%         82.442  \n",
       "16                              493,167        1.76%         55.381  \n",
       "17                              457,608        1.73%         54.550  \n",
       "18                              393,722        1.53%         48.167  \n",
       "19                              302,621        1.16%         36.530  \n",
       "20                              227,927        0.85%         26.833  \n",
       "21                              195,405        0.75%         23.659  \n",
       "22                                    -        0.35%         11.087  \n",
       "23                               72,636        0.27%          8.396  \n",
       "24                                    -        0.19%          6.125  \n",
       "25                                    -        0.19%          5.938  \n",
       "26                               42,697        0.17%          5.206  \n",
       "27                               42,756        0.16%          5.041  \n",
       "28                                    -        0.16%          4.912  \n",
       "29                                    -        0.15%          4.714  \n",
       "30                                    -        0.14%          4.283  \n",
       "31                                    -        0.12%          3.735  \n",
       "32                                    -        0.04%          1.392  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.3 Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/   \n",
    "# You have to find following details: A) Rank B) State C) GSDP(18-19)- at current prices D) GSDP(19-20)- at current prices   \n",
    "# E) Share(18-19) F) GDP($ billion)   \n",
    "# Note: - From statisticstimes home page you have to reach to economy page through code.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import requests\n",
    "import time\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "time.sleep(5)\n",
    "economy=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "economy.click()\n",
    "country=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "country.click()\n",
    "time.sleep(3)\n",
    "state=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "state.click()\n",
    "time.sleep(5)\n",
    "\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP1=[]\n",
    "GSDP2=[]\n",
    "Share=[]\n",
    "GDP=[]\n",
    "\n",
    "start=0\n",
    "end=1\n",
    "\n",
    "for page in range(start,end):\n",
    "    Rank_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[1]')\n",
    "    for i in Rank_tags:\n",
    "        try:\n",
    "            rank=i.text\n",
    "            Rank.append(rank)\n",
    "        except:\n",
    "            Rank.append('-')\n",
    "    State_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[2]')\n",
    "    for i in State_tags:\n",
    "        try:\n",
    "            state=i.text\n",
    "            State.append(state)\n",
    "        except:\n",
    "            State.append('-')\n",
    "    GSDP1_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[4]')\n",
    "    for i in GSDP1_tags:\n",
    "        try:\n",
    "            gsdp1=i.text\n",
    "            GSDP1.append(gsdp1)\n",
    "        except:\n",
    "            GSDP1.append('-')\n",
    "    GSDP2_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[3]')\n",
    "    for i in GSDP2_tags:\n",
    "        try:\n",
    "            gsdp2=i.text\n",
    "            GSDP2.append(gsdp2)\n",
    "        except:\n",
    "            GSDP2.append('-')\n",
    "    Share_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[5]')\n",
    "    for i in Share_tags:\n",
    "        try:\n",
    "            share=i.text\n",
    "            Share.append(share)\n",
    "        except:\n",
    "            Share.append('-')\n",
    "    GDP_tags=driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[6]')\n",
    "    for i in GDP_tags:\n",
    "        try:\n",
    "            gdp=i.text\n",
    "            GDP.append(gdp)\n",
    "        except:\n",
    "            GDP.append('-')\n",
    "df=pd.DataFrame({'Rank':Rank,'State':State,'GSDP(21-22) Cr INR at current prices':GSDP1,'GSDP(22-23) Cr INR at current prices':GSDP2,'Share(21-22)':Share,'GDP($ billion)':GDP})\n",
    "df.head(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6749e523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Repository Title, Repository Description, Contributors Count, Language Used]\n",
       "Index: []"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.4 Scrape the details of trending repositories on Github.com. Url = https://github.com/   \n",
    "# You have to find the following details: A) Repository title B) Repository description C) Contributors count D) Language used\n",
    "# Note: - From the home page you have to click on the trending option from Explore menu through code.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import requests\n",
    "import time\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://github.com/\")\n",
    "time.sleep(5)\n",
    "explore=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")\n",
    "explore.click()\n",
    "option=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\")\n",
    "option.click()\n",
    "time.sleep(3)\n",
    "\n",
    "Title=[]\n",
    "Description=[]\n",
    "Contributors=[]\n",
    "Language=[]\n",
    "\n",
    "start=0\n",
    "end=1\n",
    "\n",
    "for page in range(start,end):\n",
    "    Title_tags=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/h2/a')\n",
    "    for i in Title_tags:\n",
    "        try:\n",
    "            title=i.text\n",
    "            Title.append(title)\n",
    "        except NoSuchElementException:\n",
    "            Title.append('-')\n",
    "    Description_tags=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/p')\n",
    "    for i in Description_tags:\n",
    "        try:\n",
    "            description=i.text\n",
    "            Description.append(description)\n",
    "        except NoSuchElementException:\n",
    "            Description.append('-')\n",
    "    Contributors_tags=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/div/a[2]')\n",
    "    for i in Contributors_tags:\n",
    "        try:\n",
    "            contributors=i.text\n",
    "            Contributors.append(contributors)\n",
    "        except NoSuchElementException:\n",
    "            Contributors.append('-')\n",
    "    Language_tags=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/div[2]/span/span[2]')\n",
    "    for i in Language_tags:\n",
    "        try:\n",
    "            language=i.text\n",
    "            Language.append(language)\n",
    "        except NoSuchElementException:\n",
    "            Language.append('-')\n",
    "df=pd.DataFrame({'Repository Title':Title,'Repository Description':Description,'Contributors Count':Contributors,'Language Used':Language})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32f97457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q.5 Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/  You have to find the following details:\n",
    "# A) Song name B) Artist name C) Last week rank D) Peak rank E) Weeks on board\n",
    "# Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import requests\n",
    "import time\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https:/www.billboard.com/\")\n",
    "time.sleep(5)\n",
    "charts=driver.find_element(By.XPATH,\"/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f66bdefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.6 Scrape the details of Highest selling novels.   \n",
    "# A) Book name B) Author name C) Volumes sold D) Publisher E) Genre   \n",
    "# Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import requests\n",
    "import time\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "\n",
    "Book=[]\n",
    "Author=[]\n",
    "Volumes=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "for _ in range(20):\n",
    "    driver.execute_script(\"window.scrollBy(0,20)\")\n",
    "    \n",
    "start=0\n",
    "end=1\n",
    "\n",
    "for page in range(start,end):\n",
    "    Book_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in Book_tags:\n",
    "        try:\n",
    "            book=i.text\n",
    "            Book.append(book)\n",
    "        except NoSuchElementException:\n",
    "            Book.append('-')\n",
    "    Author_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in Author_tags:\n",
    "        try:\n",
    "            author=i.text\n",
    "            Author.append(author)\n",
    "        except NoSuchElementException:\n",
    "            Author.append('-')\n",
    "    Volumes_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in Volumes_tags:\n",
    "        try:\n",
    "            volumes=i.text\n",
    "            Volumes.append(volumes)\n",
    "        except NoSuchElementException:\n",
    "            Volumes.append('-')\n",
    "    Publisher_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in Publisher_tags:\n",
    "        try:\n",
    "            publisher=i.text\n",
    "            Publisher.append(publisher)\n",
    "        except NoSuchElementException:\n",
    "            Publisher.append('-')\n",
    "    Genre_tags=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in Genre_tags:\n",
    "        try:\n",
    "            genre=i.text\n",
    "            Genre.append(genre)\n",
    "        except NoSuchElementException:\n",
    "            Genre.append('-')    \n",
    "df=pd.DataFrame({'Book Name':Book,'Author Name':Author,'Volumes Sold':Volumes,'Publisher':Publisher,'Genre':Genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f43f5917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>55 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,262,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,320,650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,072,402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>313,497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>273,443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>True Detective</td>\n",
       "      <td>(2014– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>55 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>645,889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011–2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>162,078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>The OA</td>\n",
       "      <td>(2016–2019)</td>\n",
       "      <td>Drama, Fantasy, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>114,895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989– )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>433,132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Desperate Housewives</td>\n",
       "      <td>(2004–2012)</td>\n",
       "      <td>Comedy, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>138,703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name    Year Span                     Genre Run Time  \\\n",
       "0        Game of Thrones  (2011–2019)  Action, Adventure, Drama   55 min   \n",
       "1        Stranger Things  (2016–2025)    Drama, Fantasy, Horror   51 min   \n",
       "2       The Walking Dead  (2010–2022)   Drama, Horror, Thriller   44 min   \n",
       "3         13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   60 min   \n",
       "4                The 100  (2014–2020)    Drama, Mystery, Sci-Fi   43 min   \n",
       "..                   ...          ...                       ...      ...   \n",
       "95        True Detective     (2014– )     Crime, Drama, Mystery   55 min   \n",
       "96             Teen Wolf  (2011–2017)    Action, Drama, Fantasy   41 min   \n",
       "97                The OA  (2016–2019)   Drama, Fantasy, Mystery   60 min   \n",
       "98          The Simpsons     (1989– )         Animation, Comedy   22 min   \n",
       "99  Desperate Housewives  (2004–2012)    Comedy, Drama, Mystery   45 min   \n",
       "\n",
       "   Ratings      Votes  \n",
       "0      9.2  2,262,800  \n",
       "1      8.7  1,320,650  \n",
       "2      8.1  1,072,402  \n",
       "3      7.5    313,497  \n",
       "4      7.6    273,443  \n",
       "..     ...        ...  \n",
       "95     8.9    645,889  \n",
       "96     7.7    162,078  \n",
       "97     7.8    114,895  \n",
       "98     8.7    433,132  \n",
       "99     7.6    138,703  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.7 Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls512407256/\n",
    "# You have to find the following details:\n",
    "# A) Name B) Year span C) Genre D) Run time E) Ratings F) Votes\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import requests\n",
    "import time\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.imdb.com/list/ls512407256/\")\n",
    "\n",
    "Name=[]\n",
    "Year=[]\n",
    "Genre=[]\n",
    "Runtime=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "start=0\n",
    "end=1\n",
    "\n",
    "for page in range(start,end):\n",
    "    Name_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/h3/a')\n",
    "    for i in Name_tags:\n",
    "        try:\n",
    "            name=i.text\n",
    "            Name.append(name)\n",
    "        except NoSuchElementException:\n",
    "            Name.append('-')\n",
    "    Year_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/h3/span[2]')\n",
    "    for i in Year_tags:\n",
    "        try:\n",
    "            year=i.text\n",
    "            Year.append(year)\n",
    "        except NoSuchElementException:\n",
    "            Year.append('-')\n",
    "    Genre_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p/span[5]')\n",
    "    for i in Genre_tags:\n",
    "        try:\n",
    "            genre=i.text\n",
    "            Genre.append(genre)\n",
    "        except NoSuchElementException:\n",
    "            Genre.append('-') \n",
    "    Runtime_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p/span[3]')\n",
    "    for i in Runtime_tags:\n",
    "        try:\n",
    "            runtime=i.text\n",
    "            Runtime.append(runtime)\n",
    "        except NoSuchElementException:\n",
    "            Runtime.append('-')\n",
    "    Ratings_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/div[1]/div[1]/span[2]')\n",
    "    for i in Ratings_tags:\n",
    "        try:\n",
    "            ratings=i.text\n",
    "            Ratings.append(ratings)\n",
    "        except NoSuchElementException:\n",
    "            Ratings.append('-')\n",
    "    Votes_tags=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[4]/span[2]')\n",
    "    for i in Votes_tags:\n",
    "        try:\n",
    "            votes=i.text\n",
    "            Votes.append(votes)\n",
    "        except NoSuchElementException:\n",
    "            Votes.append('-')\n",
    "df=pd.DataFrame({'Name':Name,'Year Span':Year,'Genre':Genre,'Run Time':Runtime,'Ratings':Ratings,'Votes':Votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5fe23c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No. of Instances</th>\n",
       "      <th>No. of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>16</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Raisin</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real, Integer</td>\n",
       "      <td>900</td>\n",
       "      <td>7</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>30</td>\n",
       "      <td>/199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wine Quality</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4898</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset Name                  Data Type  \\\n",
       "0                                  Iris                    Tabular   \n",
       "1                      Dry Bean Dataset               Multivariate   \n",
       "2                         Heart Disease               Multivariate   \n",
       "3            Rice (Cammeo and Osmancik)               Multivariate   \n",
       "4                                 Adult               Multivariate   \n",
       "5                                Raisin               Multivariate   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)               Multivariate   \n",
       "7                                  Wine                    Tabular   \n",
       "8                          Wine Quality               Multivariate   \n",
       "9                              Diabetes  Multivariate, Time-Series   \n",
       "\n",
       "                         Task              Attribute Type No. of Instances  \\\n",
       "0              Classification                        Real              150   \n",
       "1              Classification               Integer, Real            13611   \n",
       "2              Classification  Categorical, Integer, Real              303   \n",
       "3              Classification                        Real             3810   \n",
       "4              Classification        Categorical, Integer            48842   \n",
       "5              Classification               Real, Integer              900   \n",
       "6              Classification                        Real              569   \n",
       "7              Classification               Integer, Real              178   \n",
       "8  Classification, Regression                        Real             4898   \n",
       "9              Classification        Categorical, Integer                1   \n",
       "\n",
       "  No. of Attribute  Year  \n",
       "0                4  1988  \n",
       "1               16  2020  \n",
       "2               13  1988  \n",
       "3                7  2019  \n",
       "4               14  1996  \n",
       "5                7  2023  \n",
       "6               30  /199  \n",
       "7               13  1991  \n",
       "8               11  2009  \n",
       "9               20     -  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.8 Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/\n",
    "# You have to find the following details:\n",
    "# A) Dataset name B) Data type C) Task D) Attribute type E) No of instances F) No of attribute G) Year\n",
    "# Note: - from the home page you have to go to the Show All Dataset page through code.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import requests\n",
    "import time\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "time.sleep(3)\n",
    "explore=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]\")\n",
    "explore.click()\n",
    "\n",
    "Dataset_urls=[]\n",
    "Name=[]\n",
    "Type=[]\n",
    "Task=[]\n",
    "Attribute=[]\n",
    "Instances=[]\n",
    "Number=[]\n",
    "Year=[]\n",
    "\n",
    "start=0\n",
    "end=1\n",
    "\n",
    "for page in range(start,end):\n",
    "    url=driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]')\n",
    "    for i in url:\n",
    "        Dataset_urls.append(i.get_attribute(\"href\"))\n",
    "for url in Dataset_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        name=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[1]/div[2]/div/h1\")\n",
    "        Name.append(name.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('-')\n",
    "    try:\n",
    "        typ=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[1]/p\")\n",
    "        Type.append(typ.text)\n",
    "    except NoSuchElementException:\n",
    "        Type.append('-')\n",
    "    try:\n",
    "        task=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[3]/p\")\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    try:\n",
    "        attribute=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[4]/p\")\n",
    "        Attribute.append(attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute.append('-')\n",
    "    try:\n",
    "        instances=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[5]/p\")\n",
    "        Instances.append(instances.text)\n",
    "    except NoSuchElementException:\n",
    "        Instances.append('-')\n",
    "    try:\n",
    "        number=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[6]/p\")\n",
    "        Number.append(number.text)\n",
    "    except NoSuchElementException:\n",
    "        Number.append('-')\n",
    "    try:\n",
    "        year=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[1]/div[2]/h2\")\n",
    "        Year.append(year.text[16:20])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n",
    "df=pd.DataFrame({'Dataset Name':Name,'Data Type':Type,'Task':Task,'Attribute Type':Attribute,'No. of Instances':Instances,'No. of Attribute':Number,'Year':Year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06490f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
